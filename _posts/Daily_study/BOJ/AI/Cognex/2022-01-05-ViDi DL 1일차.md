---
title: "ViDi 1일차"
categories:
  - Daily Study
tags:
  - Al
  - Cognex
  - ViDi
---
## 기본 CNN + 간단한 설명 

### End to end Learning CNNs
- 학습된 CNN 모델은 새롭게 들어온 Data에 대해 Pass에 가까운 건지 Fail에 가까운 건지 판단할 수 있다.
- 그리고 "결과에 대한 근거를 설명하기가 매우 애매? 복잡하다." 라는 한계점이 존재한다.
- 모델의 형태 자체가 Hidden Layer(은닉층)가 존재하는 블랙박스 형태의 구조이기 때문이다.
- CNN 모델은 세부 Parameter 설정을 통해 가중치를 다르게해서 다른 용도로 사용되도록 만들수 있다. 

### Data
- 요즘에는 클라우드에서 Image Set을 다운받아 사용할 수 있다.  
- Deep Learning에는 많은 양의 이미지가 필요하다.
- GPU같은 경우 Nvidia의 제품을 사용한다.

(:비전 검사기를 만들때(여담)


사진 몇장 가져와서 이거 만들어줘 해서 다 만들어서 들고갔는데 고객이 원하는 검사가 이나라서 현장에서 알고리즘을 다 뜯어 고쳐야하는 경우도 많았다...)

### 현장
- 현장에서는 딥러닝을 제대로 하기 위해서는 석박사를 고용해 연구를 진행해야 하는데 이렇게 진행하더라도 제대로 결과가 나오기는 힘들고 나온다고 해도 근거를 설명할 수 없어 애매한 경우가 많다.
- 딥러닝이 잘 못하는 것을 Rule Base기반의 알고리즘이 더 잘 하는 경우도 있다. 

자 이제 코그넥스는 이런 불편한 점을 최대한 개선했다고 한다. 

## ViDi Deep Learning
- 딥러닝을 모르더라도 사용할 수 있도록 직관적인 용어를 사용한다. 
- 세 가지 기능으로 구분되지만 같은 Core를 사용하기 때문에 Parameter set가 동일하다
- <span style="color:blue">Blue : Find Locate</span>
- <span style="color:red">Red : 결함 찾기</span>
- <span style="color:green">Green : Classification</span>
- 사람이 해야하는 일은 Labeling하는 거다.
- 지도학습 비지도학습이 구분되어 있다. 
### 개발 
- C or C++, .Net 프레임워크로 개발할 수 있다. 이때 .Net은 wap로 개발 해야한다.

### 제품 소개
- Train 라이센스는 2가지(Standard, Advanced)가 있고 Run 라이센스는 3가지(Base,Standard, Advanced)가 있다. 그리고 Run에는 Train 라이센스가 포함되어 있지 않다.
- Base -> 1 GPU & Runtime만 사용할 수 있다. Training에는 매우 시간이 많이 걸린다.
- Standard -> 1 GPU
- Advanced -> 4 GPU


(Locate를 찾는 Blue 대신에 Rule Base 알고리즘을 쓰고 있다면 그게 더 정확할 수도 있다. )


# ViDi Suite Program 
#### 기본 설정 
- GPU의 메모리를 사용하려면 Options에서 설정해주는 것이 좋다.
- 기본적으로는 GPU의 2/3만 쓰고 더 쓰고 싶다면 직접 용량을 적어주면 된다. 
- 알고리즘을 관리하는 곳은 왼쪽의 WorkSpace다. 
- Help - Expert Mode 클릭시에 파라미터, About 클릭시에 라이센스, 사용 가능한 GPU를 확인할 수 있다. 
- 오른쪽의 Display 패널은 View 패널이라 불린다.  
- Display 패널 옆의 Database OverView는 학습에 사용되는 Data의 전체적은 정보를 확인할 수 있다. 

#### Workspaces
- 각각의 Tools는 Stream이라는 이름으로 관리된다. 

#### 이미지 가져오기
- View 패널의 Add click 
- Database 메뉴의 ADD image or images(from folder)

#### Tool 추가
- 중간의 Input 클릭
- 모든 툴은 가장 먼저 적용할 영역(ROI)를 설정해야 한다. 
- ROI 설정시 Color 이미지는 Defalut로 흑백으로 바뀐다.(1 Channel) 컬러로 학습시키고 싶으면 바꿀 수 있다. (1 -> 3 Channel 변경하기)



## <span style="color:red">Red : Analyze Tool Unsupervised Learning</span>
- 정상적인 이미지만 학습 시켜 불량인 이미지가 들어오면 걸러내는 작업. 
- 기존의 Rule Base 작업으로는 찾기 힘든 결함을 발견하는 것에 주로 사용된다. 
- 기본적인 단계는 다음과 같다. 
    1. Collect
    2. Train
    3. Vaildate

![image](https://user-images.githubusercontent.com/38587274/148175252-d34c78d2-ea60-4517-829f-ad167708e868.png)

- 이때 데이터는 중복을 허용하기 때문에 주의가 필요하다.(중복 검사를 X)
- Labeling은 사진 선택 후 큰 사진에 왼쪽 마우스를 클릭하면 된다. 
- 또 사진이 너무 많은 경우 파일 이름으로도 구분 가능하다. 
- Display Pannel에서 not 'bad'를 search 하면 파일 이름에 'bad'가 들어가지 않은 이미지만 볼 수 있다.
- 그리고 Actions for N Views에서 Label Views에서 Good, Bad로 레이블링을 진행할 수 있다.
- Tools Parameters에 Training Set도 설정해줘야 한다. 
- 뇌모양 -> Train 시작
- 가위 모양 -> Process 수정 버튼? 


### 결과 보는 법
- 초록색 -> Good
- 빨강색 -> Bad
- 회색 -> Inter (애매 ??)
- 숫자값 -> 절대값으로 1이상의 값으로 표시되다. 

# Tool Parameter
### 개념 
#### Sampling
- 어떻게 데이터를 샘플링 할지를 설정하는 매개변수.
#### Training
- 모델을 최적화(학습)시키는 것에 관련된 매개변수로 해당 파라미터에 따라 모델이 더 정확해질 수도 있고 않좋아 질수도 있다. 
#### Perturbation
- 데이터에 조금의 변형이 있더라도 모델이 판별할 수 있게 해준다.
#### Processing 
- 학습이 완료된 모델을 사용할 때 원하는 결과를 얻게 해준다. 

### Unsupervised vs Supervised
- Unsupervised : 정상인 데이터만 학습에 사용하기 때문에 정상범위에서 벗어난 것을 모두 찾을 수 있음.
- Supervised : 정상 데이터 + 불량인 데이터 + 불량의 유형을 학습 데이터로 사용하기 때문에 데이터에 없는 불량은 찾기 힘들다 수 없다. 하지만 불량의 유형에 따라 찾을 수 있다는 장점이 있다.

## Sampling Parameters 설정
### Feature Size
- <span style="color:blue">Blue : Find Locate</span> -> Detected된 Feature의 Size
- <span style="color:red">Red : 결함 찾기</span> -> 최소 (15,15)
- <span style="color:green">Green : Classification</span> -> 애매.. 함.. 

### Color
 - 요거 설정은 RGB(A)로 가는데 A는 나머지 부분을 Masking 할때 사용한다. 그리고 ViDi는 기본적으로 컬러가 들어와도 BGR Channel(흑백)로 바꾼다.

### Border Type
- 찾고 싶은 부분 주위를 BlackBox or Replicate 모드로 바꿀 수 있다.   

### Masking mode 
- 1. Transparent - mask를 사용하지 않을 때
- 2. Mask - mask된 부분을 무시하고 싶을때 사용 
- 3. Overlay - Alpha 채널을 사용하고 해당 채널에 Mask 정보가 있을때 사용



## Training Parameters 설정
- Training Set : Training에 사용할 데이터 수(이때 Random Sampling을 통해 데이터를 무작위로 뽑을 수도 있다.)
- Epoch : 반복횟수 (Defalut : 50)
- Capacity : 모델의 크기 (Huge ~ Tiny)
    - Huge : 복잡한(미세한) 부분을 찾을 경우
    - Tiny : 간단한 것을 찾을때
- Training Passes (1 ~ 4)
    - Complex Area에 얼마만큼의 가중치(탐색하는 횟 수)를 줄 것이냐 
- Low Precision
    - 정확한 결과가 나오지 않아도 될 경우 

### Leaning Curves
- Leaning -> Loss값이 빠르게 낮아진다.
- Fine Tuning -> Loss값이 천천히 낮아진다.
- Overfitting -> 모델이 학습 데이터에만 익숙해진 상태로 조금만 다른 데이터가 들어오면 Fail로 판단한 위험이 있다. 

# 내일 오후에 제대로 된 매개변수를 찾을 수 있는 Tool 설명 예정 


## Perturbation Parameters 설정
- 교육 자료 P.104에 각 종 파라미터의 적용 예시가 나와 있다. 
- Rotation(각도)
- Scale(크기))
- Aspect-Ratio
- Shear( 기울기)
- Flip(뒤집기)
- Luminance
- Contrast
- Invert Contrast

## Processing Parameters 설정
- Sampling Density
    - 값이 높을수록 좀 더 촘촘하게 검사를 진행한다.
- iterations (1~4)
    - 뭔가 있을거 같다고 판단되는 부분만 해당 값 만큼 더 찾아 본다. 
- Threshold
    - 정상, 불량의 경계값 ㅇ 해당 값을 그래프 상에서, 직접 숫자로 변경 가능 하겨 
- BaseLine 
     - Noise가 많은 곳의 경우 
## 결과 부분 
- Actual 
    - Labeling이 된 Data들의 분류 결과


# Supervised 모델 -> 패턴찾기 ㅇ 
- 가공육, 알약, 자동차 부품 등 다양한 분야에서 사용 
- 불량인 이미지를 Labeling 할때 Grouping 할 수 있는 방법이 있음.
    - Actions for N views -> add image set to 를 클릭해서 한번에 분류할 수 있다.

### Edit Region
![image](https://user-images.githubusercontent.com/38587274/148175794-c06c02a3-de1c-41f1-914a-bc7c7e60e818.png)


# Labeling
- Line
- Circle
- Fill -> 클릭한 부분과 동일한 밝기값을 가지는 부분을 모두 색칠한다. 
- Eraser
- simple Regions 체크시 -> 테두리만 색칠하면 안쪽까지 모두 색칠된다. 
- Training set에는 Labeling 된 것들만 들어간다.
- 유형별 최소 100장의 Data가 필요하다.
- Feature size는 찾는 결함의 최소 크기로 맞춰야지 해당 크기 이상의 결함을 찾을 수 있다.

### 학습 후 결과 화면 
![image](https://user-images.githubusercontent.com/38587274/148174986-82d07a86-ea18-4b17-b3dd-371c4895135f.png)

## 첫 번째 방법 
- 조금만 Region 설정 후 모델을 한번 학습시키고 결과가 안좋은 데이터만 다시 Region 설정을 해서 사용할 수도 있다. 
- Good인데 Bad로 판별되는 높은 놈, Bad인데 Good으로 판별되는 놈들을 Training Set에 포함시켜 학습시킬 수 있다. 
- 이렇게 해서도 잘 안된다면 각종 변수들을 변경해줘야 한다. 

## 추가적인 방법
- Scores Graph에서 Threshold를 재설정하고 Scores Graph밑에 있는 CufusionMatrix에서 진짜 감도 못잡는 데이터들만 labeling 해줘도 된다.
- 그리고 4 ~ 5 번 정도는 랜덤으로 Labeling된 데이터를 넣어서 결과가 잘 나오면 그때 사용해야 한다. 


# Tool Chaining 
- 약간 Ensemble 모델 느낌이 난다. ?? 

# Run Time
- Training 단에서 얻은 정보를 바탕으로 Application단에서 Processing 파라미터를 조절할 수 있다. 


##### 저장 방법 그냥 저장시 PC에 파일 말고 다른거 뭔지는 모르겠는데 어쨌든 그걸로 저장된다.



# <span style="color:blue">Blue Locate</span>
- Tool chain 방법 -> Blue Tool로 위치를 특정한 다음에 Red Tool로 검사를 하게 할 수 있다.
- 물고기의 머리 꼬리를 각각 따로 학습시켜 그 위치가 정확하면 물고기라고 인식할 수 있게도 한다. 
- > 기본적인 단계는 다음과 같다. 
    1. Collect
    2. Identify
    3. Train
    4. Vaildate
- Feature Naming과 Labeling을 하면 각 이름마다 색을 다르게 지정할 수 있고 결과 화면에서도 구분할 수 있게 나타난다. 

## Tutorial 03 - 나사 위치 찾기 
- ROI는 나사가 없는 부분은 제외한다.
- Feature Size -> 직접 설정 할 수도 있고 밑에 투명한 박스로 조절 할 수도 있다.
- Feature의 정중앙을 클릭하면 Box가 딱 맞게 쳐지고 해당 Feature의 Name을 변경할 수 있다. 
![image](https://user-images.githubusercontent.com/38587274/148178778-090a25b2-25f1-43d6-a7ca-be474e87ce80.png)

- Features 
    - > Oriented : 회전시켜서 Labeling 할때
    - > Scaled : 크기를 변경시켜서 Labeling 할때 ? 
    - > 두 개를 잡아서 머리 - 나사선 처럼 학습시켜 나사의 위치를 찾아 볼 수도 있다.  
- Box 칠때 비치는 것도 영향을 준다.. 

### Processing Parameters 
- Precision --> 해당 물체의 정확한 정보를 알아햐 할 때는 0~1%로 설정해야하고 빠르게 찾아야 할 경우에는 값을 크게하면 된다. 